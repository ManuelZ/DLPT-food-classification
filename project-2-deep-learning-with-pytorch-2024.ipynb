{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66638,"databundleVersionId":7378729,"sourceType":"competition"},{"sourceId":8598645,"sourceType":"datasetVersion","datasetId":5144265},{"sourceId":8605341,"sourceType":"datasetVersion","datasetId":5149136},{"sourceId":8607360,"sourceType":"datasetVersion","datasetId":5150523},{"sourceId":8607789,"sourceType":"datasetVersion","datasetId":5150807},{"sourceId":8644524,"sourceType":"datasetVersion","datasetId":5177271}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n\n#### Maximum Points: 100\n\n<div>\n    <table>\n        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Log</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>\n","metadata":{}},{"cell_type":"code","source":"!pip install --quiet lightning\n!pip install --quiet albumentations","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:14.337826Z","iopub.execute_input":"2024-06-09T05:39:14.338176Z","iopub.status.idle":"2024-06-09T05:39:43.751107Z","shell.execute_reply.started":"2024-06-09T05:39:14.338147Z","shell.execute_reply":"2024-06-09T05:39:43.750059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard Library imports\nfrom pathlib import Path\nfrom dataclasses import dataclass\nimport os\n\n# External imports\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.modules.batchnorm import _BatchNorm\nfrom torch.utils.data import Dataset, DataLoader\n\nimport lightning as pl\nfrom lightning.pytorch.loggers import TensorBoardLogger\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\nfrom lightning.pytorch.callbacks import BackboneFinetuning, BaseFinetuning\n\nfrom torchmetrics import MeanMetric\nfrom torchmetrics.classification import MulticlassAccuracy\nfrom torchmetrics.classification import MulticlassConfusionMatrix\n\nfrom torchvision import models\nfrom torchvision.utils import make_grid\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:43.753141Z","iopub.execute_input":"2024-06-09T05:39:43.753459Z","iopub.status.idle":"2024-06-09T05:39:53.320282Z","shell.execute_reply.started":"2024-06-09T05:39:43.753430Z","shell.execute_reply":"2024-06-09T05:39:53.319541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Configuration</font>","metadata":{}},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass TrainingConfiguration:\n    '''\n    Describe configuration of the training process\n    '''\n    LOAD_MODEL = True\n    TRAINED_MODEL_PATH = \"/kaggle/input/resnet50-epoch-184/fine-tuning-resnet50-epoch-184.ckpt\"\n    GRADIENT_ACCUMULATION = 1\n    EPOCHS: int = 60\n    WARMUP_EPOCHS: int = 10\n    MAX_LR: float = 1e-2\n    WEIGHT_DECAY:float = 2e-5\n    PRECISION: str = \"16-mixed\"\n    TRAIN_SPLIT: float = 0.75\n    BATCH_SIZE: int = 32\n    PATIENCE: int = 10\n    LAYERS= [4, 5, 6, 7]  # Possible values: 4, 5, 6, 7\n    FAST_DEV_RUN = False\n    MODEL_NAME: str = \"resnet50\"\n    WEIGHTS: str = \"DEFAULT\"\n    \n@dataclass(frozen=True)\nclass DataConfiguration:\n    ROOT_FOLDER: str = \"/kaggle/input/opencv-pytorch-classification-project-2\"\n    NUM_CORKERS: int = 4\n    NUM_CLASSES:int = 13\n    TARGET_SIZE: int = 256\n        \ntrain_config = TrainingConfiguration()\ndata_config = DataConfiguration()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:53.321427Z","iopub.execute_input":"2024-06-09T05:39:53.321999Z","iopub.status.idle":"2024-06-09T05:39:53.331288Z","shell.execute_reply.started":"2024-06-09T05:39:53.321972Z","shell.execute_reply":"2024-06-09T05:39:53.330427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Data Loader</font>","metadata":{}},{"cell_type":"code","source":"class KenyanFood13Dataset(Dataset):\n    \"\"\"\n    Generic Dataset class for semantic segmentation datasets.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_path,\n        images_folder,\n        image_ids,\n        labels=None,\n        transforms=None,\n    ):\n\n        self.data_path = data_path\n        self.images_folder = images_folder\n        self.image_ids = image_ids\n        self.labels = labels\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        label = self.labels[idx] if self.labels is not None else None\n\n        # Get image \n        image_path = os.path.join(self.data_path, self.images_folder, f\"{image_id}.jpg\")\n\n        # Load image\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n           \n        #For the prediction step\n        if label is None:\n            label = str(image_id)\n            \n        if self.transforms is not None:\n            transformed = self.transforms(image=image)\n            return transformed['image'], label\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:53.333625Z","iopub.execute_input":"2024-06-09T05:39:53.333903Z","iopub.status.idle":"2024-06-09T05:39:53.349098Z","shell.execute_reply.started":"2024-06-09T05:39:53.333874Z","shell.execute_reply":"2024-06-09T05:39:53.348325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KenyaDataModule(pl.LightningDataModule):\n\n    def __init__(self, batch_size, num_workers=1):\n        super().__init__()\n        \n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        \n        self.common_transforms = A.Compose(\n            [\n                A.Resize(height=data_config.TARGET_SIZE, width=data_config.TARGET_SIZE, p=1),\n                A.CenterCrop(height=224, width=224, p=1),\n                A.Normalize(),\n                ToTensorV2(),\n            ]\n        )\n\n        self.train_transforms = A.Compose(\n            [\n                #A.RandomResizedCrop(data_config.TARGET_SIZE, data_config.TARGET_SIZE),\n                A.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3),\n                A.ToGray(p=0.1),\n                A.HorizontalFlip(),\n                A.VerticalFlip(),\n                A.RandomRotate90(),\n                A.ShiftScaleRotate(\n                    border_mode=cv2.BORDER_CONSTANT,\n                    rotate_limit=10,\n                    scale_limit=0.0,\n                    value=0,\n                    p=0.75,\n                ),\n                A.ElasticTransform(\n                    alpha=120,\n                    sigma=6,\n                    alpha_affine=8,\n                    border_mode=cv2.BORDER_CONSTANT,\n                    value=0,\n                    interpolation=cv2.INTER_LINEAR,\n                    p=0.5,\n                ),\n                A.GridDistortion(\n                    num_steps=5,\n                    distort_limit=0.05,\n                    border_mode=cv2.BORDER_CONSTANT,\n                    value=0,\n                    interpolation=cv2.INTER_LINEAR,\n                    p=0.5,\n                ),\n                self.common_transforms\n            ]\n        )\n\n        self.valid_transforms = A.Compose([self.common_transforms])\n        self.test_transforms = A.Compose([self.common_transforms])\n\n    def prepare_data(self):\n        \"\"\"\n        This function handles downloads and any data processing.\n        This function makes sure that when you use multiple GPUs,\n        you don't download multiple datasets or apply double manipulations to the data.\n        \"\"\"\n        pass\n\n    def setup(self, stage=None):\n\n        train_csv_path = Path(data_config.ROOT_FOLDER) / \"train.csv\"\n        test_csv_path = Path(data_config.ROOT_FOLDER) / \"test.csv\"\n\n        train_df = pd.read_csv(train_csv_path)\n        test_df = pd.read_csv(test_csv_path)\n        \n        self.whole_dataset = KenyanFood13Dataset(\n            data_config.ROOT_FOLDER,\n            \"images/images\",\n            train_df.id,\n        )\n\n        # Encode classes as integers\n        self.le = LabelEncoder()\n        y = self.le.fit_transform(train_df[\"class\"])\n        y = torch.Tensor(y).to(torch.int64)\n        \n        # Image ids\n        X = train_df.id\n               \n        # Stratified split into training and validation sets\n        sss = StratifiedShuffleSplit(n_splits=1, train_size=train_config.TRAIN_SPLIT, random_state=0)\n        for train_index, valid_index in sss.split(X, y):\n            train_ids, valid_ids, train_y, valid_y = X[train_index], X[valid_index], y[train_index], y[valid_index]\n\n        test_ids = test_df.id\n        \n        self.train_dataset = KenyanFood13Dataset(\n            data_config.ROOT_FOLDER,\n            \"images/images\",\n            train_ids.tolist(),\n            labels=train_y,\n            transforms=self.train_transforms,\n        )\n        \n        self.valid_dataset = KenyanFood13Dataset(\n            data_config.ROOT_FOLDER,\n            \"images/images\",\n            valid_ids.tolist(),\n            labels=valid_y,\n            transforms=self.valid_transforms,\n        )\n\n        self.predict_dataset = KenyanFood13Dataset(\n            data_config.ROOT_FOLDER,\n            \"images/images\",\n            test_ids.tolist(),\n            transforms=self.test_transforms,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            drop_last=True,\n            num_workers=self.num_workers,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.valid_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            drop_last=True,\n            num_workers=self.num_workers,\n        )\n\n    def predict_dataloader(self):\n        return DataLoader(\n            self.predict_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            drop_last=True,\n            num_workers=self.num_workers,\n        )","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:53.350271Z","iopub.execute_input":"2024-06-09T05:39:53.350605Z","iopub.status.idle":"2024-06-09T05:39:53.370013Z","shell.execute_reply.started":"2024-06-09T05:39:53.350573Z","shell.execute_reply":"2024-06-09T05:39:53.369168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denormalize(tensors):\n    \"\"\"\n    Denormalize image tensors back to range [0.0, 1.0]\n    \n    From: Deep Learning with PyTorch - OpenCV University\n    \"\"\"\n\n    mean = torch.Tensor([0.485, 0.456, 0.406])\n    std = torch.Tensor([0.229, 0.224, 0.225])\n    \n    tensors = tensors.clone()\n    for c in range(3):\n        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n\n    return torch.clamp(tensors.cpu(), 0.0, 1.0)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:53.371101Z","iopub.execute_input":"2024-06-09T05:39:53.371347Z","iopub.status.idle":"2024-06-09T05:39:53.382923Z","shell.execute_reply.started":"2024-06-09T05:39:53.371325Z","shell.execute_reply":"2024-06-09T05:39:53.382210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization of some augmented images \n\nNote: The normalization is removed to be able to perceive the other transformations.","metadata":{}},{"cell_type":"code","source":"dm = KenyaDataModule(batch_size=25)\ndm.setup()\n\ndataloader = dm.train_dataloader()\n\nimages, labels = next(iter(dataloader))\nprint(f\"Images batch shape: {images.size()}\")\nprint(f\"Labels batch shape: {labels.size()}\")\n\nfig, ax = plt.subplots(figsize=(12,12))\nax.set_xticks([]); ax.set_yticks([])\n\nimages = denormalize(images)\n\nax.imshow(make_grid(images, nrow=5).permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:39:53.383850Z","iopub.execute_input":"2024-06-09T05:39:53.384085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Train and Validation</font>\n","metadata":{}},{"cell_type":"code","source":"class FineTuningWithResNet(pl.LightningModule):\n    def __init__(\n        self,\n        resnet_model_name=\"resnet18\",\n        weights=\"DEFAULT\",\n        max_lr=0.01,\n        num_classes=10,\n    ):\n        \"\"\"\n        Modified from: Deep Learning with PyTorch - OpenCV University\n        \"\"\"\n        \n        super().__init__()\n\n        self.save_hyperparameters()\n\n        # Init the backbone of a pretrained Resnet\n        resnet = getattr(models, self.hparams.resnet_model_name)(weights=self.hparams.weights)\n        layers = list(resnet.children())[:-1]\n        self.backbone = nn.Sequential(*layers)\n        \n        # Add a classifier head\n        self.classifier = nn.Linear(in_features=resnet.fc.in_features, out_features=self.hparams.num_classes)\n\n        # Initializing the required metric objects.\n        self.mean_train_loss = MeanMetric()\n        self.mean_train_acc = MulticlassAccuracy(num_classes=self.hparams.num_classes, average=\"micro\")\n        self.mean_valid_loss = MeanMetric()\n        self.mean_valid_acc = MulticlassAccuracy(num_classes=self.hparams.num_classes, average=\"micro\")\n        \n        self.confusion_matrix = MulticlassConfusionMatrix(num_classes=self.hparams.num_classes)\n\n    \n    def forward(self, x):\n        \"\"\" \"\"\"\n        x = self.backbone(x).flatten(1)\n        x = self.classifier(x)\n        return x\n\n\n    def training_step(self, batch, *args, **kwargs):\n        \"\"\" \"\"\"\n        \n        data, target = batch\n\n        # Get prediction\n        output = self(data)\n\n        # Calculate batch loss\n        loss = F.cross_entropy(output, target)\n\n        # Batch Predictions\n        pred_batch = output.detach().argmax(dim=1)\n\n        self.mean_train_loss.update(loss, weight=data.shape[0])\n        self.mean_train_acc.update(pred_batch, target)\n\n        # self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True, logger=True)\n        # self.log(\"train/batch_acc\", self.mean_train_acc, prog_bar=True, logger=True)\n\n        return loss\n\n    \n    def on_train_epoch_end(self):\n        \"\"\"Calculate epoch level metrics for the train set\"\"\"\n        \n        self.log(\"train/loss\", self.mean_train_loss, prog_bar=True, logger=True)\n        self.log(\"train/acc\", self.mean_train_acc, prog_bar=True, logger=True)\n        self.log(\"step\", self.current_epoch, logger=True)\n\n    \n    def validation_step(self, batch, *args, **kwargs):\n        \"\"\" \"\"\"\n        \n        data, target = batch\n\n        # get prediction\n        output = self(data)\n\n        loss = F.cross_entropy(output, target)\n\n        # Batch Predictions\n        pred_batch = output.argmax(dim=1)\n\n        self.mean_valid_loss.update(loss, weight=data.shape[0])\n        self.mean_valid_acc.update(pred_batch, target)\n        self.confusion_matrix.update(pred_batch, target)\n    \n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        data, imageid = batch\n        output = self(data)\n        pred = output.detach().argmax(dim=1)\n        return imageid, pred\n        \n\n    def on_validation_epoch_end(self):\n        \"\"\"Calculate epoch level metrics for the validation set\"\"\"\n\n        self.log(\"valid/loss\", self.mean_valid_loss, prog_bar=True, logger=True)\n        self.log(\"valid/acc\", self.mean_valid_acc, prog_bar=True, logger=True)\n        self.log(\"step\", self.current_epoch, logger=True)\n\n        \n    def configure_optimizers(self):\n        \"\"\" \"\"\"\n        \n        optimizer = torch.optim.SGD(self.parameters(), weight_decay=train_config.WEIGHT_DECAY)\n        \n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.hparams.max_lr,\n            steps_per_epoch=self.trainer.estimated_stepping_batches,\n            epochs=train_config.EPOCHS,\n        )\n        \n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                # The unit of the scheduler's step size, could also be 'step'.\n                # 'epoch' updates the scheduler on epoch end whereas 'step'\n                # updates it after a optimizer update.\n                \"interval\": \"step\",\n                # How many epochs/steps should pass between calls to `scheduler.step()`.\n                # 1 corresponds to updating the learning rate after every epoch/step.\n                \"frequency\": 1,\n                # Metric to monitor for schedulers like `ReduceLROnPlateau`\n                \"monitor\": \"valid/loss\",\n                # If set to `True`, will enforce that the value specified 'monitor'\n                # is available when the scheduler is updated, thus stopping\n                # training if not found. If set to `False`, it will only produce a warning\n                \"strict\": True,\n                # If using the `LearningRateMonitor` callback to monitor the\n                # learning rate progress, this keyword can be used to specify\n                # a custom logged name\n                \"name\": None,\n            },\n        }\n\n    \n    def unfreeze_head(self):\n        \"\"\"\n        This is not overriding anything, it's just a method I created.\n        \"\"\"\n\n        for param in self.classifier.parameters():\n            param.requires_grad = True\n\n    \n    def unfreeze_backbone_layers(self, layers: list[int]):\n        \"\"\"\n        This is not overriding anything, it's just a method I created.\n        \"\"\"\n\n        # self.backbone has 4 Sequential layers, from backbone[4] to backbone[7]\n        for l in layers:\n            backbone_layer = self.backbone[l]\n            modules = BaseFinetuning.flatten_modules(backbone_layer)\n                            \n            for module in modules:\n                if isinstance(module, _BatchNorm):\n                    module.track_running_stats = True\n                # recursion could yield duplicate parameters for parent modules w/ parameters so disabling it\n                for param in module.parameters(recurse=False):\n                    param.requires_grad = True\n\n    \n    def freeze_backbone(self):\n        \"\"\" \"\"\"\n        BaseFinetuning.freeze(self.backbone, train_bn=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_module = KenyaDataModule(\n    batch_size=train_config.BATCH_SIZE,\n    num_workers=data_config.NUM_CORKERS\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n    monitor='valid/acc',\n    mode=\"max\",\n    filename='fine-tuning-resnet50-epoch-{epoch:02d}',\n    auto_insert_metric_name=False,\n    save_weights_only=True\n)\n\n\nearly_stopping_callback = EarlyStopping(\n    monitor=\"valid/loss\",\n    min_delta=1e-3,\n    patience=train_config.PATIENCE\n)\n\n\ncallbacks=[\n    early_stopping_callback,                                                         \n    checkpoint_callback,\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n    accelerator=\"auto\", \n    devices=\"auto\",  \n    strategy=\"auto\", \n    max_epochs=train_config.EPOCHS,  \n    precision = train_config.PRECISION,\n    callbacks=callbacks,\n    logger=TensorBoardLogger(\"logs\", name=train_config.MODEL_NAME),\n    accumulate_grad_batches=train_config.GRADIENT_ACCUMULATION,\n    fast_dev_run=train_config.FAST_DEV_RUN,\n    #log_every_n_steps=10,\n    #limit_train_batches=1,\n    #limit_val_batches=1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Experiment</font>\n","metadata":{}},{"cell_type":"code","source":"if train_config.LOAD_MODEL:\n    \n    if Path(train_config.TRAINED_MODEL_PATH).exists():\n        model = FineTuningWithResNet.load_from_checkpoint(train_config.TRAINED_MODEL_PATH)\n        model.freeze_backbone()\n        model.unfreeze_backbone_layers(train_config.LAYERS)\n        model.unfreeze_head()\n        print(f\"Model loaded: '{train_config.TRAINED_MODEL_PATH}'\")\n    \n    else:\n        raise Exception(\"Model doesn't exist\")\n\nelse:\n    model = FineTuningWithResNet(\n        resnet_model_name=train_config.MODEL_NAME,\n        weights=train_config.WEIGHTS,\n        num_classes=data_config.NUM_CLASSES,\n        max_lr=train_config.MAX_LR,\n    )\n    \n    model.freeze_backbone()\n    \n    trainer.fit_loop.max_epochs=train_config.WARMUP_EPOCHS","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:42:58.570646Z","iopub.execute_input":"2024-06-09T05:42:58.571599Z","iopub.status.idle":"2024-06-09T05:42:59.344488Z","shell.execute_reply.started":"2024-06-09T05:42:58.571561Z","shell.execute_reply":"2024-06-09T05:42:59.343450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(21, workers=True)\ntrainer.fit(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:42:59.346122Z","iopub.execute_input":"2024-06-09T05:42:59.346418Z","iopub.status.idle":"2024-06-09T05:42:59.350316Z","shell.execute_reply.started":"2024-06-09T05:42:59.346395Z","shell.execute_reply":"2024-06-09T05:42:59.349423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FineTuningWithResNet.load_from_checkpoint(checkpoint_callback.best_model_path)\nmodel.eval()\nmodel.freeze()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:42:59.351238Z","iopub.execute_input":"2024-06-09T05:42:59.351518Z","iopub.status.idle":"2024-06-09T05:42:59.361823Z","shell.execute_reply.started":"2024-06-09T05:42:59.351487Z","shell.execute_reply":"2024-06-09T05:42:59.361034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.validate(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:43:00.059193Z","iopub.execute_input":"2024-06-09T05:43:00.059863Z","iopub.status.idle":"2024-06-09T05:43:27.418216Z","shell.execute_reply.started":"2024-06-09T05:43:00.059827Z","shell.execute_reply":"2024-06-09T05:43:27.417205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig_, ax_ = model.confusion_matrix.plot()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:43:27.419856Z","iopub.execute_input":"2024-06-09T05:43:27.420223Z","iopub.status.idle":"2024-06-09T05:43:28.730283Z","shell.execute_reply.started":"2024-06-09T05:43:27.420182Z","shell.execute_reply":"2024-06-09T05:43:28.729363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare predictions","metadata":{}},{"cell_type":"code","source":"results = trainer.predict(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:43:28.741799Z","iopub.execute_input":"2024-06-09T05:43:28.742082Z","iopub.status.idle":"2024-06-09T05:43:45.198057Z","shell.execute_reply.started":"2024-06-09T05:43:28.742059Z","shell.execute_reply":"2024-06-09T05:43:45.197118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nimageids = []\nfor res in results:\n    ids, preds = res\n    imageids.extend(ids)\n    predictions.extend(preds.tolist())\n    \npredictions = data_module.le.inverse_transform(predictions)\ndf = pd.DataFrame({\"id\":imageids, \"class\":predictions})\ndf.to_csv(\"predictions.csv\", index=False)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:43:45.199509Z","iopub.execute_input":"2024-06-09T05:43:45.199819Z","iopub.status.idle":"2024-06-09T05:43:45.223028Z","shell.execute_reply.started":"2024-06-09T05:43:45.199788Z","shell.execute_reply":"2024-06-09T05:43:45.221979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">Kaggle Profile Link</font>\n\n\n**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n","metadata":{}}]}